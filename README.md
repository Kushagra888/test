# 🖼️ Image Captioning with BLIP (Hugging Face + PyTorch)

This project uses the [BLIP (Bootstrapped Language Image Pretraining)](https://huggingface.co/Salesforce/blip-image-captioning-base) model from Hugging Face to generate natural language captions from images using PyTorch.


---

## 📦 Installation

Clone the repo and install dependencies:

```bash
git clone https://github.com/Kushagra888/test.git
cd test
pip install -r requirements.txt
